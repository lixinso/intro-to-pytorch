{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "loss_function_binary_cross_entropy_with_logits.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOp90Rnlj/NT9mrPUvjh0in",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lixinso/sample-intro-to-pytorch/blob/master/loss_function_binary_cross_entropy_with_logits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t98dQpvIHOUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://pytorch.org/docs/stable/nn.functional.html\n",
        "# https://pytorch.org/docs/stable/nn.html#torch.nn.BCEWithLogitsLoss\n",
        "# https://medium.com/@zhang_yang/how-is-pytorchs-binary-cross-entropy-with-logits-function-related-to-sigmoid-and-d3bd8fb080e7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRvjrKNMoiqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIOpu2GvowKK",
        "colab_type": "text"
      },
      "source": [
        "binary_cross_entropy_with_logits\n",
        "\n",
        "Function that measures Binary Cross Entropy between target and output logits.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Qp4vVEHnFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfiuJZbVjylO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_loss(input, target):\n",
        "\n",
        "  loss = F.binary_cross_entropy_with_logits(input, target)\n",
        "  loss.backward()\n",
        "  print(\"input\", input.cpu().detach().numpy())\n",
        "  print(\"target\", target.cpu().detach().numpy())\n",
        "  print(\"loss\", loss.cpu().detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejnrA9-IkaJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a7345fa3-0a8d-4624-eee8-3f257089804f"
      },
      "source": [
        "input = torch.randn(3, requires_grad=True)\n",
        "target = torch.empty(3).random_(2)\n",
        "cal_loss(input, target)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input [0.06618073 0.11251571 0.91884685]\n",
            "target [1. 1. 0.]\n",
            "loss 0.85122156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mraLhrt8k8ZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "706937c9-6da3-44d4-9b24-422b3259b4c7"
      },
      "source": [
        "input = torch.tensor([0.9, 0.1, 0.1], requires_grad=True)\n",
        "target = torch.tensor([1.0, 0.0, 0.0])\n",
        "cal_loss(input, target)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input [0.9 0.1 0.1]\n",
            "target [1. 0. 0.]\n",
            "loss 0.60998243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taNEpJV6llFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "73657f90-9950-4e6c-914d-fe5d79e85e32"
      },
      "source": [
        "input = torch.tensor([0.33, 0.33, 0.33], requires_grad=True)\n",
        "target = torch.tensor([1.0, 0.0, 0.0])\n",
        "cal_loss(input, target)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input [0.33 0.33 0.33]\n",
            "target [1. 0. 0.]\n",
            "loss 0.7616984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2Jwtn9vmZpy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "46a09c34-85a3-4d33-bcba-161b1655e72c"
      },
      "source": [
        "input = torch.tensor([1.0, 0.0, 0.0], requires_grad=True)\n",
        "target = torch.tensor([1.0, 0.0, 0.0])\n",
        "cal_loss(input, target)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input [1. 0. 0.]\n",
            "target [1. 0. 0.]\n",
            "loss 0.56651866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDbvu2Czn1GA",
        "colab_type": "text"
      },
      "source": [
        "**The loss value is smaller if the the prediction is closer to the labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOHh5UMGuDBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Break down the detailed logic\n",
        "def sigmoid(x): \n",
        "  return (1 + (-x).exp()).reciprocal()\n",
        "\n",
        "def binary_cross_entropy(pred, y): \n",
        "  return -(pred.log()*y + (1-y)*(1-pred).log()).mean()\n",
        "\n",
        "def sigmoid_then_binary_cross_entropy(input, target):\n",
        "  pred = sigmoid(input)\n",
        "  loss = binary_cross_entropy(pred, target)\n",
        "  print(\"loss:\", loss)\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGlMK0BFuyhb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6fa745a4-0986-47a1-b201-8d7a8c4b4448"
      },
      "source": [
        "sigmoid_then_binary_cross_entropy(input, target)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: tensor(0.5665, grad_fn=<NegBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5665, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX3CTUwdwhkt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "0c886348-e08c-49f0-ae3a-a48813f86906"
      },
      "source": [
        "batch_size, n_classes = 10, 4\n",
        "x = torch.randn(batch_size, n_classes)\n",
        "x.shape\n",
        "\n",
        "target = torch.randint(n_classes, size=(batch_size,), dtype=torch.long)\n",
        "target\n",
        "\n",
        "y = torch.zeros(batch_size, n_classes)\n",
        "y[range(y.shape[0]), target]=1\n",
        "y\n",
        "\n",
        "print(\"x:\\n\", x)\n",
        "print(\"y:\\n\", y)\n",
        "\n",
        "print(\"Resut from breakdown logic\")\n",
        "sigmoid_then_binary_cross_entropy(x, y)\n",
        "\n",
        "print(\"Resut from F logic\")\n",
        "F.binary_cross_entropy_with_logits(x, y)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x:\n",
            " tensor([[-0.5760, -0.1714,  0.8396, -1.1253],\n",
            "        [ 0.6703, -1.0028,  0.6055, -0.3187],\n",
            "        [-0.1560,  1.3475, -0.7083, -0.5969],\n",
            "        [-0.8557, -0.0873,  0.1444, -1.4816],\n",
            "        [-0.1840, -0.4293, -1.0453,  0.3899],\n",
            "        [-0.7339,  0.1211,  1.2247, -0.6315],\n",
            "        [-0.1392,  0.0396,  0.2456, -0.1327],\n",
            "        [ 0.1174,  1.9707, -0.3957,  0.5086],\n",
            "        [-0.5482, -2.0041,  0.5604, -0.2339],\n",
            "        [-0.1246,  1.1398,  1.3749, -0.1067]])\n",
            "y:\n",
            " tensor([[0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1.],\n",
            "        [0., 0., 1., 0.],\n",
            "        [0., 0., 1., 0.],\n",
            "        [1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1.],\n",
            "        [1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0.],\n",
            "        [0., 0., 1., 0.]])\n",
            "Resut from breakdown logic\n",
            "loss: tensor(0.6902)\n",
            "Resut from F logic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    }
  ]
}